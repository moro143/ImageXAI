% !TEX encoding = UTF-8 Unicode 
% !TEX root = praca.tex

\chapter*{Metodyka badań}

\section*{Przygotowanie środowiska}

Do przeprowadzenia eksperymentów z wybranymi metodami XAI wymagane jest odpowiednie przygotowanie środowiska programistycznego.
W naszej pracy wykorzystujemy  następujące narzędzia i biblioteki:
\begin{itemize}
	\item \textbf{Python} - wysokopoziomowy język programowania, który jest szeroko stosowany w dziedzinie nauki o danych i uczenia maszynowego.
	      Jest to główny język używany w naszych badaniach.
	\item \textbf{TensorFlow} - popularna biblioteka open-source do uczenia maszynowego, która jest szeroko stosowana w dziedzinie uczenia maszynowego do tworzenia i trenowania modeli głębokich.
	\item \textbf{LIME} - biblioteka do generowania lokalnie interpretowalnych wyjaśnień dla decyzji modelu. (lime\_image)
	\item \textbf{SHAP} - biblioteka oparta na teorii gier, która oblicza wartości Shapleya, określająca wpływ poszczególnych cech na wynik modelu.
	\item \textbf{numpy} - biblioteka do obliczeń numerycznych, która jest szeroko stosowana.
	\item \textbf{matplotlib} - biblioteka do tworzenia wykresów i wizualizacji danych, która jest szeroko stosowana w dziedzinie uczenia maszynowego.
	\item \textbf{scikit-image} - biblioteka do przetwarzania obrazów, która zawiera wiele funkcji do przetwarzania obrazów.
	\item \textbf{Pandas} - biblioteka do manipulacji i analizy danych, które oferuje struktury danyc hi narzędzia do przetwarzania danych tabelarycznych.
	      Jest szczególnie użyteczna do zarządzania i analizowania zbiorów danych używanych w badaniach.
\end{itemize}
Środowisko to pozwala na tworzenie i analizowanie wyjaśnień dla już istniejących modeli głębokiego uczenia.
Narzędzia te umożliwiają także wizualizację wyników, co jest kluczowe dla zrozumienia i prezentacji działania zastosowanych metod XAI.

\section*{Jak zostały wykorzystane metody}
W celu zrozumienia, jak różne metody XAI mogą wyjaśnić decyzje modeli głębokiego uczenia w kontekście klasyfikacji obrazów, wykorzystaliśmy trzy różne techniki: LIME, SHAP oraz GradCAM.
Poniżej przedstawiamy sposób, w jaki każda z tech metod została zastosowana w naszych badaniach.

\subsection*{LIME}

\subsection*{SHAP}

\subsection*{Grad-CAM}

\section*{Wybór parametrów}
Wybór odopwiednich parametrów jest kluczowym etapem w procesie tworzenia i oceny modeli głębokiego uczenia oraz metod wyjaśnialnej sztucznej inteligencji (XAI).
Parametry mają bezpośredni wpływ na jakość, dokładność i interpretowalność wyników generowanych przez modele i metody XAI.
W tej sekcji omówimy, jakie parametry zostały wybrane dla każdej z zastosowanych metod (LIME, SHAP i GradCAM), oraz jak te parametry wpływają na wyniki i interpretacje uzyskane w naszych badaniach

\subsection*{LIME}
LimeImageExplainer(kernel width=0.25, kernel=exponential kernel, feature selection='auto', random state=None)
kernel width for exponential kernel
kernel - exponential kernel
future selection - auto | other: forward selection, lasso path, none, auto
random state

explain instance(image, classifier fn=model, labels=top label, top labels=1, num features=100000?, num samples=1000, batch size=10?, segmentation fn=???, random seed=42)
labels, top labels - dla jednaj najwazniejszej labelki
num features - default 100 000
num samples - 1000

\subsection*{SHAP}

\subsection*{GradCAM}

\section*{Algorytmy i miary jakości}

W tej sekcji opisujemy algorytmy oraz miary jakości użyte do oceny skuteczności metod wyjaśnialnej sztucznej inteligencji (XAI) w zadaniu klasyfikacji obrazów.
Możemy je podzielić na dwie kategorie, oparte na prawdzie oraz oparte na modelu.

\textbf{Miary oparte na prawdzie} są to miary, które oceniają skuteczność metod XAI na podstawie faktycznych wartości docelowych.

Natomiast \textbf{miary oparte na modelu} oceniają skuteczność metod XAI do wytłumaczania modelu.

\begin{enumerate}
	\item \textbf{IOU} (Intersection over Union): Algorytm IOU jest powszechnie stosowany w zadaniach segmentacji obrazów do oceny jakości detekcji obrazów.
	      Oblicza on stosunek powierzchni przecięcia dwóch obszarów do ich sumy.
	      W naszym kontekście, IOU może być używany do oceny zgodności obszarów wyznaczonych przez metody XAI z rzeczywistymi obiektami na obrazie.

	\item \textbf{Confidence change}: Miara ta ocenia zmianę pewności klasyfikacji na obrazach po zastosowaniu metod XAI.
	      Jest to różnica między pewnościami klasyfikacji na oryginalnych obrazach a pewnościami klasyfikacji na obrazach zmodyfikowanych z użyciem XAI.
	      Dzięki tej mierze możemy ocenić, czy metody XAI wpływają na zmianę pewności klasyfikacji.
	      Obszar wyznaczony przez metody XAI powinien minimalnie zmniejszyć pewność klasyfikacji lub ją zwiększyć.
	      Natomiast obszar poza wyznaczonym obszarem powinien drastycznie zmniejszyć pewność klasyfikacji.
\end{enumerate}

Poprzez zastosowanie tych algorytmów i miar jakości, będziemy w stanie ocenić skuteczność metod XAI w wyjaśnianiu klasyfikacji obrazów oraz ich wpływ na jakość klasyfikacji.

