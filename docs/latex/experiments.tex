% !TEX encoding = UTF-8 Unicode 
% !TEX root = praca.tex

\chapter*{Badania}

W ninjejszym rozdziale przedstawimy wyniki badań mających na celu porównanie różnych metod XAI stosowanych do wyjaśniania decyzji modeli głębokiego uczenia w kontekście klasyfikacji obrazów.
W badaniach wykozystano LIME, SHAP oraz GradCAM, aby zrozumieć, w jaki sposób te techniki różnią się pod względem generowanych wyjaśnień, dokładności oraz interpretowalności.

Analiza porównawcza została przeprowadzona w oparciu o kilka kluczowych kryteriów:
\begin{itemize}
	\item Średnia redukcja pewności
	\item Średni procentowy wzrost pewności
	\item IoU
\end{itemize}
Podczas badań każdy z powyższych kryteriów został dokładnie oceniony i zanalizowany, aby uzyskać pełny obraz mocnych i słabych stron poszczególnych metod XAI.
Przedstawione wyniki mają na celu dostarczenie wwglądu w to, jak różne techniki wyjaśniania modeli mogą być stosowane w praktyce raz jak wybrać odpowiednią metodę w zależności od konkretnych wymagań aplikacji.

\input{experiments/coherence}

\input{experiments/benchmarking}

\input{experiments/combine}

%\input{experiments/other_dataset}

%\input{experiments/other_models}

%\section*{Ocena poszczegóĺnych algorytmów}
%Ocena poszczególnych algorytmów.
%Porównanie wyników metod pod kątem ich zdolności do dostarczania zrozumiałych i precyzyjnych wyjaśnień.
%Słabe i mocne strony każdej metody.
%Czas wykonania eksperymentów oraz złożoność obliczeniowa

