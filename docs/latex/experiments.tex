% !TEX encoding = UTF-8 Unicode 
% !TEX root = praca.tex

\chapter*{Badania}

W tym rozdziale przedstawione zostały wyniki badań mających na celu porównanie różnych metod XAI stosowanych do wyjaśniania decyzji modeli głębokiego uczenia w kontekście klasyfikacji obrazów.
W badaniach wykorzystano LIME, SHAP oraz GradCAM, aby zrozumieć, w jaki sposób te techniki różnią się pod względem generowanych wyjaśnień, ich dokładności oraz interpretowalności.

Podczas badań skoncentrowano się na trzech głównych aspektach: zmianie pewności, wielkości wyjaśnień oraz IoU (Intersection over Union).
Analiza tych miar pozwoliła na lepsze zrozumienie, jak każda metoda XAI wpływa na interpretowalność modeli oraz ich skuteczność w wyjaśnianiu decyzji.

Wyniki tych badań dostarczyły cennych infromacji na temat różnic między poszczególnymi technikami XAI oraz pozwoliły na wyciągnięcie wniosków dotyczących najlepszych praktyk w ich stosowaniu.
Poprzez przedstawienie tych wyników, dążono do lepszego zrozumienia wpływu wyboru odpowiedniej metody XAI na interpretowalność i skuteczność modeli głębokiego uczenia w praktyce.

\input{experiments/coherence}

\input{experiments/size}

\input{experiments/benchmarking}

\input{experiments/combine}

%\input{experiments/other_dataset}

%\input{experiments/other_models}

%\section*{Ocena poszczegóĺnych algorytmów}
%Ocena poszczególnych algorytmów.
%Porównanie wyników metod pod kątem ich zdolności do dostarczania zrozumiałych i precyzyjnych wyjaśnień.
%Słabe i mocne strony każdej metody.
%Czas wykonania eksperymentów oraz złożoność obliczeniowa

